{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e36bd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75ef352",
   "metadata": {},
   "source": [
    "Below I have code to collect all the parquet files in a list and than concataning the files together and printing them in a wrong way. But because I didn't want to keep doing it. It is commented out. I than have the file being read into them.Than I wanted to check shape and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "729c823f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get a list of all Parquet files in the directory\n",
    "# files = glob.glob(os.path.expanduser('~/Downloads/*.parquet'))\n",
    "# print(files)  # printing file names to verify\n",
    "\n",
    "# # Initialize an empty list to hold DataFrames\n",
    "# df_list = []\n",
    "\n",
    "# # Read each file into a DataFrame and append it to the list\n",
    "# for file in files:\n",
    "#     df_read = pd.read_parquet(file)\n",
    "#     df_list.append(df_read)\n",
    "\n",
    "# # Concatenate all DataFrames in the list\n",
    "# if df_list:  # Checking if the list is not empty\n",
    "#     df_rows = pd.concat(df_list, ignore_index=True)\n",
    "#     # Write the combined DataFrame to a new Parquet file\n",
    "#     df_rows.to_parquet('combined.parquet')\n",
    "# else:\n",
    "#     print(\"No parquet files found in the directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a48baf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39656098, 19)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet('combined.parquet')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e34d5afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime',\n",
       "       'passenger_count', 'trip_distance', 'RatecodeID', 'store_and_fwd_flag',\n",
       "       'PULocationID', 'DOLocationID', 'payment_type', 'fare_amount', 'extra',\n",
       "       'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge',\n",
       "       'total_amount', 'congestion_surcharge', 'airport_fee'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca93ab1",
   "metadata": {},
   "source": [
    "## Logical tests \n",
    "###  logical test 1  times being accurate or correct.\n",
    "Ok I did a few logical tests to  check integrity of the data. So the first test is ensuring that the times for drop off are after pick up time and creating a column to indicate if its invalid trip durations. Ant than wanted to check when it is.I have this amount when I run it. So this is a big proportion that I think should be dropped. But analysing them all together to see if all logical tests are valid for all rows. [13613 rows x 20 columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b5f406f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid trip duration detected in the following records:\n",
      "          VendorID tpep_pickup_datetime tpep_dropoff_datetime  \\\n",
      "1780087          1  2022-10-16 23:48:14   2022-10-16 00:30:42   \n",
      "2418647          1  2022-10-22 10:00:00   2022-10-22 09:26:56   \n",
      "3543244          6  2022-10-01 05:10:58   2022-10-01 05:10:24   \n",
      "3543780          6  2022-10-01 10:10:16   2022-10-01 10:10:06   \n",
      "3543799          6  2022-10-01 10:10:51   2022-10-01 10:10:37   \n",
      "...            ...                  ...                   ...   \n",
      "39655298         6  2022-05-31 17:05:26   2022-05-31 17:05:24   \n",
      "39655461         6  2022-05-31 18:05:38   2022-05-31 18:05:00   \n",
      "39655541         6  2022-05-31 18:05:17   2022-05-31 18:05:06   \n",
      "39655599         6  2022-05-31 19:05:45   2022-05-31 19:05:10   \n",
      "39656003         6  2022-05-31 22:05:31   2022-05-31 22:05:22   \n",
      "\n",
      "          passenger_count  trip_distance  RatecodeID store_and_fwd_flag  \\\n",
      "1780087               1.0          21.70         2.0                  N   \n",
      "2418647               1.0           0.50        99.0                  N   \n",
      "3543244               NaN           2.02         NaN               None   \n",
      "3543780               NaN           5.71         NaN               None   \n",
      "3543799               NaN           6.55         NaN               None   \n",
      "...                   ...            ...         ...                ...   \n",
      "39655298              NaN           2.04         NaN               None   \n",
      "39655461              NaN           0.68         NaN               None   \n",
      "39655541              NaN           8.54         NaN               None   \n",
      "39655599              NaN          11.28         NaN               None   \n",
      "39656003              NaN          10.63         NaN               None   \n",
      "\n",
      "          PULocationID  DOLocationID  payment_type  fare_amount  extra  \\\n",
      "1780087            132           142             1        52.00   3.75   \n",
      "2418647            185           242             1        16.20   0.00   \n",
      "3543244            265            39             0        30.20   0.00   \n",
      "3543780            265            15             0        19.35   0.00   \n",
      "3543799            265           218             0        25.34   0.00   \n",
      "...                ...           ...           ...          ...    ...   \n",
      "39655298           265           170             0        40.20   0.00   \n",
      "39655461           265           141             0        45.20   0.00   \n",
      "39655541           265            22             0        32.06   0.00   \n",
      "39655599           265           183             0        46.20   0.00   \n",
      "39656003           265           133             0        35.90   0.00   \n",
      "\n",
      "          mta_tax  tip_amount  tolls_amount  improvement_surcharge  \\\n",
      "1780087       0.5        12.6          6.55                    0.3   \n",
      "2418647       0.5         0.0          0.00                    0.3   \n",
      "3543244       0.5         0.0          0.00                    0.3   \n",
      "3543780       0.5         0.0          0.00                    0.3   \n",
      "3543799       0.5         0.0          0.00                    0.3   \n",
      "...           ...         ...           ...                    ...   \n",
      "39655298      0.5         0.0          0.00                    0.3   \n",
      "39655461      0.5         0.0          0.00                    0.3   \n",
      "39655541      0.5         0.0          0.00                    0.3   \n",
      "39655599      0.5         0.0          0.00                    0.3   \n",
      "39656003      0.5         0.0          0.00                    0.3   \n",
      "\n",
      "          total_amount  congestion_surcharge  airport_fee  invalid_time  \n",
      "1780087          75.70                   2.5         1.25          True  \n",
      "2418647          17.00                   0.0         0.00          True  \n",
      "3543244          31.00                   NaN          NaN          True  \n",
      "3543780          20.15                   NaN          NaN          True  \n",
      "3543799          26.14                   NaN          NaN          True  \n",
      "...                ...                   ...          ...           ...  \n",
      "39655298         41.00                   NaN          NaN          True  \n",
      "39655461         46.00                   NaN          NaN          True  \n",
      "39655541         32.86                   NaN          NaN          True  \n",
      "39655599         47.00                   NaN          NaN          True  \n",
      "39656003         36.70                   NaN          NaN          True  \n",
      "\n",
      "[13613 rows x 20 columns]\n"
     ]
    }
   ],
   "source": [
    "# Check if the dropoff time is earlier than the pickup time for any record\n",
    "invalid_records = df[df['tpep_dropoff_datetime'] < df['tpep_pickup_datetime']]\n",
    "\n",
    "# Add a column 'invalid_time' to indicate invalid trip durations\n",
    "df['invalid_time'] = df['tpep_dropoff_datetime'] < df['tpep_pickup_datetime']\n",
    "\n",
    "# Print the records with invalid trip durations, if any\n",
    "invalid_records = df[df['invalid_time']]\n",
    "\n",
    "# Print the invalid records, if any\n",
    "if not invalid_records.empty:\n",
    "    print(\"Invalid trip duration detected in the following records:\")\n",
    "    print(invalid_records)\n",
    "else:\n",
    "    print(\"All trip durations are valid.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20dfd36",
   "metadata": {},
   "source": [
    "### Logical tests 2 trip distance ensuring it is not 0 or below.\n",
    "Next test is to see if the trip distance is not below 0 as it would not make sense that a negative taxi journey would happen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e59c6d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid trip distances detected in the following records:\n",
      "          VendorID tpep_pickup_datetime tpep_dropoff_datetime  \\\n",
      "293              2  2022-10-01 00:46:38   2022-10-01 00:46:44   \n",
      "294              2  2022-10-01 00:46:38   2022-10-01 00:46:44   \n",
      "362              1  2022-10-01 00:32:03   2022-10-01 00:49:48   \n",
      "431              1  2022-10-01 00:41:34   2022-10-01 00:44:51   \n",
      "520              2  2022-10-01 00:59:21   2022-10-01 00:59:25   \n",
      "...            ...                  ...                   ...   \n",
      "39655095         2  2022-05-31 17:46:00   2022-05-31 17:51:00   \n",
      "39655713         2  2022-05-31 19:02:47   2022-05-31 19:02:57   \n",
      "39655730         2  2022-05-31 19:25:00   2022-05-31 19:25:09   \n",
      "39655857         2  2022-05-31 21:18:44   2022-05-31 21:19:03   \n",
      "39656093         2  2022-05-31 23:40:19   2022-06-01 00:01:20   \n",
      "\n",
      "          passenger_count  trip_distance  RatecodeID store_and_fwd_flag  \\\n",
      "293                   1.0            0.0         2.0                  N   \n",
      "294                   1.0            0.0         2.0                  N   \n",
      "362                   1.0            0.0         1.0                  N   \n",
      "431                   1.0            0.0         1.0                  N   \n",
      "520                   1.0            0.0         5.0                  N   \n",
      "...                   ...            ...         ...                ...   \n",
      "39655095              NaN            0.0         NaN               None   \n",
      "39655713              NaN            0.0         NaN               None   \n",
      "39655730              NaN            0.0         NaN               None   \n",
      "39655857              NaN            0.0         NaN               None   \n",
      "39656093              NaN            0.0         NaN               None   \n",
      "\n",
      "          PULocationID  DOLocationID  payment_type  ...  extra  mta_tax  \\\n",
      "293                249           249             3  ...    0.0     -0.5   \n",
      "294                249           249             3  ...    0.0      0.5   \n",
      "362                215           131             1  ...    0.0      0.5   \n",
      "431                114           114             3  ...    3.0      0.5   \n",
      "520                265           265             1  ...    0.0      0.0   \n",
      "...                ...           ...           ...  ...    ...      ...   \n",
      "39655095            13            13             0  ...    0.0      0.5   \n",
      "39655713           140           140             0  ...    0.0      0.5   \n",
      "39655730           224           224             0  ...    0.0      0.5   \n",
      "39655857            50            50             0  ...    0.0      0.5   \n",
      "39656093            36           181             0  ...    0.0      0.5   \n",
      "\n",
      "          tip_amount  tolls_amount  improvement_surcharge  total_amount  \\\n",
      "293             0.00           0.0                   -0.3        -55.30   \n",
      "294             0.00           0.0                    0.3         55.30   \n",
      "362             0.00           0.0                    0.3         23.00   \n",
      "431             0.00           0.0                    0.3          6.30   \n",
      "520            26.66           0.0                    0.3        159.96   \n",
      "...              ...           ...                    ...           ...   \n",
      "39655095        5.07           0.0                    0.3         27.93   \n",
      "39655713        5.91           0.0                    0.3         32.54   \n",
      "39655730        4.13           0.0                    0.3         22.79   \n",
      "39655857        1.00           0.0                    0.3         14.30   \n",
      "39656093        1.00           0.0                    0.3         22.77   \n",
      "\n",
      "          congestion_surcharge  airport_fee  invalid_time  \\\n",
      "293                       -2.5          0.0         False   \n",
      "294                        2.5          0.0         False   \n",
      "362                        0.0          0.0         False   \n",
      "431                        2.5          0.0         False   \n",
      "520                        0.0          0.0         False   \n",
      "...                        ...          ...           ...   \n",
      "39655095                   NaN          NaN         False   \n",
      "39655713                   NaN          NaN         False   \n",
      "39655730                   NaN          NaN         False   \n",
      "39655857                   NaN          NaN         False   \n",
      "39656093                   NaN          NaN         False   \n",
      "\n",
      "          invalid_trip_distance  \n",
      "293                        True  \n",
      "294                        True  \n",
      "362                        True  \n",
      "431                        True  \n",
      "520                        True  \n",
      "...                         ...  \n",
      "39655095                   True  \n",
      "39655713                   True  \n",
      "39655730                   True  \n",
      "39655857                   True  \n",
      "39656093                   True  \n",
      "\n",
      "[574059 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# Check for Invalid Trip Distances\n",
    "df['invalid_trip_distance'] = df['trip_distance'] <= 0\n",
    "\n",
    "# Print the records with invalid trip distances, if any\n",
    "invalid_trip_distances = df[df['invalid_trip_distance']]\n",
    "if not invalid_trip_distances.empty:\n",
    "    print(\"Invalid trip distances detected in the following records:\")\n",
    "    print(invalid_trip_distances)\n",
    "else:\n",
    "    print(\"All trip distances are valid.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e51491",
   "metadata": {},
   "source": [
    "### logical test 3 fare amount consistency \n",
    "I made sure that the fare adds up so that it all makes sense and than creating a column again to see if its true or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4eca3c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All fare amounts are consistent.\n"
     ]
    }
   ],
   "source": [
    "# Check for Fare Amount Consistency\n",
    "fare_columns = ['fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge', 'congestion_surcharge', 'airport_fee']\n",
    "df['inconsistent_fare_amount'] = abs(df['fare_amount'] - df[fare_columns].sum(axis=1)) < 0.01\n",
    "\n",
    "# Print the records with inconsistent fare amounts, if any\n",
    "inconsistent_fares = df[df['inconsistent_fare_amount']]\n",
    "if  inconsistent_fares.empty:\n",
    "    print(\"Inconsistent fare amounts detected in the following records:\")\n",
    "    print(inconsistent_fares)\n",
    "else:\n",
    "    print(\"All fare amounts are consistent.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5533d9fa",
   "metadata": {},
   "source": [
    "### Logical tests  4 make sure total amount is above 0. \n",
    "A journey would not be negative money so just to identify these rows and see if they are consistent with other rows identified and just having a column to say true or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3188755",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative total amounts detected in the following records:\n",
      "          VendorID tpep_pickup_datetime tpep_dropoff_datetime  \\\n",
      "86               2  2022-10-01 00:52:07   2022-10-01 01:02:44   \n",
      "110              2  2022-10-01 00:29:57   2022-10-01 00:34:37   \n",
      "162              2  2022-10-01 00:31:37   2022-10-01 00:32:53   \n",
      "293              2  2022-10-01 00:46:38   2022-10-01 00:46:44   \n",
      "319              2  2022-10-01 00:06:08   2022-10-01 00:48:23   \n",
      "...            ...                  ...                   ...   \n",
      "39638854         2  2022-05-26 15:17:09   2022-05-26 15:18:19   \n",
      "39639116         2  2022-05-26 16:20:04   2022-05-26 17:29:38   \n",
      "39650635         2  2022-05-30 01:18:00   2022-05-30 01:36:00   \n",
      "39651466         2  2022-05-30 12:02:00   2022-05-30 12:47:00   \n",
      "39654046         2  2022-05-31 10:35:00   2022-05-31 10:38:00   \n",
      "\n",
      "          passenger_count  trip_distance  RatecodeID store_and_fwd_flag  \\\n",
      "86                    1.0           2.83         1.0                  N   \n",
      "110                   1.0           0.31         1.0                  N   \n",
      "162                   1.0           0.31         1.0                  N   \n",
      "293                   1.0           0.00         2.0                  N   \n",
      "319                   1.0          17.05         1.0                  N   \n",
      "...                   ...            ...         ...                ...   \n",
      "39638854              NaN           0.24         NaN               None   \n",
      "39639116              NaN           1.39         NaN               None   \n",
      "39650635              NaN           0.93         NaN               None   \n",
      "39651466              NaN           4.00         NaN               None   \n",
      "39654046              NaN           0.15         NaN               None   \n",
      "\n",
      "          PULocationID  DOLocationID  payment_type  ...  tip_amount  \\\n",
      "86                 141            79             4  ...        0.00   \n",
      "110                264           264             4  ...        0.00   \n",
      "162                138           138             4  ...        0.00   \n",
      "293                249           249             3  ...        0.00   \n",
      "319                238           175             4  ...        0.00   \n",
      "...                ...           ...           ...  ...         ...   \n",
      "39638854            50            50             0  ...        4.30   \n",
      "39639116            79           211             0  ...       15.79   \n",
      "39650635           209            79             0  ...        0.00   \n",
      "39651466           263           125             0  ...        0.00   \n",
      "39654046           143           143             0  ...        1.00   \n",
      "\n",
      "          tolls_amount  improvement_surcharge  total_amount  \\\n",
      "86                0.00                   -0.3        -14.30   \n",
      "110               0.00                   -0.3         -8.30   \n",
      "162               0.00                   -0.3         -5.55   \n",
      "293               0.00                   -0.3        -55.30   \n",
      "319              -6.55                   -0.3        -60.85   \n",
      "...                ...                    ...           ...   \n",
      "39638854          0.00                    0.3        -23.68   \n",
      "39639116          0.00                    0.3        -75.20   \n",
      "39650635          0.00                    0.3        -16.10   \n",
      "39651466          0.00                    0.3        -30.28   \n",
      "39654046          0.00                    0.3        -14.31   \n",
      "\n",
      "          congestion_surcharge  airport_fee  invalid_time  \\\n",
      "86                        -2.5         0.00         False   \n",
      "110                       -2.5         0.00         False   \n",
      "162                        0.0        -1.25         False   \n",
      "293                       -2.5         0.00         False   \n",
      "319                       -2.5         0.00         False   \n",
      "...                        ...          ...           ...   \n",
      "39638854                   NaN          NaN         False   \n",
      "39639116                   NaN          NaN         False   \n",
      "39650635                   NaN          NaN         False   \n",
      "39651466                   NaN          NaN         False   \n",
      "39654046                   NaN          NaN         False   \n",
      "\n",
      "          invalid_trip_distance  inconsistent_fare_amount  \\\n",
      "86                        False                     False   \n",
      "110                       False                     False   \n",
      "162                       False                     False   \n",
      "293                        True                     False   \n",
      "319                       False                     False   \n",
      "...                         ...                       ...   \n",
      "39638854                  False                     False   \n",
      "39639116                  False                     False   \n",
      "39650635                  False                     False   \n",
      "39651466                  False                     False   \n",
      "39654046                  False                     False   \n",
      "\n",
      "          negative_total_amount  \n",
      "86                         True  \n",
      "110                        True  \n",
      "162                        True  \n",
      "293                        True  \n",
      "319                        True  \n",
      "...                         ...  \n",
      "39638854                   True  \n",
      "39639116                   True  \n",
      "39650635                   True  \n",
      "39651466                   True  \n",
      "39654046                   True  \n",
      "\n",
      "[255706 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "# Check for Reasonable Total Amounts\n",
    "df['negative_total_amount'] = df['total_amount'] < 0\n",
    "\n",
    "# Print the records with negative total amounts, if any\n",
    "negative_total_amounts = df[df['negative_total_amount']]\n",
    "if not negative_total_amounts.empty:\n",
    "    print(\"Negative total amounts detected in the following records:\")\n",
    "    print(negative_total_amounts)\n",
    "else:\n",
    "    print(\"All total amounts are reasonable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7df8964",
   "metadata": {},
   "source": [
    "## All logical tests together combined\n",
    "Ok I just wanted to see how many issues were so i got Next is to see if there is an overlap of it so could just be some trips arent recorded correctly and that all of these factors could identifty that.\n",
    "Column Counts:\n",
    "invalid_trip_distance       574059\n",
    "inconsistent_fare_amount      9152\n",
    "negative_total_amount       255706\n",
    "dtype: int64\n",
    "All columns have at least one True value: True\n",
    "Number of records with all columns as True or partially True: 796029"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfb4499f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Counts:\n",
      "invalid_trip_distance       574059\n",
      "inconsistent_fare_amount      9152\n",
      "negative_total_amount       255706\n",
      "invalid_time                 13613\n",
      "dtype: int64\n",
      "All columns have at least one True value: True\n",
      "Number of records with all columns as True or partially True: 809363\n"
     ]
    }
   ],
   "source": [
    "# Count the number of True values in each column\n",
    "column_counts = df[['invalid_trip_distance', 'inconsistent_fare_amount', 'negative_total_amount','invalid_time']].sum()\n",
    "\n",
    "# Check if all columns have at least one True value\n",
    "all_columns_have_true = all(column_counts > 0)\n",
    "\n",
    "# Check the number of records that have all columns as True or partially True\n",
    "all_columns_true_records = df[( df['invalid_time'] | df['invalid_trip_distance'] | df['inconsistent_fare_amount'] | df['negative_total_amount'])].shape[0]\n",
    "\n",
    "# Print the results\n",
    "print(\"Column Counts:\")\n",
    "print(column_counts)\n",
    "print(\"All columns have at least one True value:\", all_columns_have_true)\n",
    "print(\"Number of records with all columns as True or partially True:\", all_columns_true_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a335864",
   "metadata": {},
   "source": [
    "Ok below is just deleting all the rows that have True in all of the categories just to see if there is an overlap because in some there was. So to elimante those rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78a2ef8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Delete rows where all columns are True\n",
    "df = df[~(df['invalid_time'] & df['invalid_trip_distance'] & df['inconsistent_fare_amount'] & df['negative_total_amount'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f9828a",
   "metadata": {},
   "source": [
    "Error checking to see if there was any. In some of the tests I ran there was so Idk why this happened only once or twice or some of them would be like 10 or so rows. Another time I ran it, it was 9000 rows were deleted so yeah just for me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea74ff89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Counts after deletion:\n",
      "invalid_time                 13613\n",
      "invalid_trip_distance       574059\n",
      "inconsistent_fare_amount      9152\n",
      "negative_total_amount       255706\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "column_counts_after_deletion = df[['invalid_time','invalid_trip_distance', 'inconsistent_fare_amount', 'negative_total_amount']].sum()\n",
    "# Print the results\n",
    "print(\"Column Counts after deletion:\")\n",
    "print(column_counts_after_deletion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557a18fb",
   "metadata": {},
   "source": [
    "Deleting all these rows because they make no sense if they are true so just deleting all those rows. As it runs the integrity of the data. That these could not be possible. Than below that checking how many were true. So i got 0 everytime I ran it so all were deleted. And than im going to drop those columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a33a30e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['invalid_trip_distance']]\n",
    "df=df[~df['inconsistent_fare_amount']]\n",
    "df=df[~df['negative_total_amount']]\n",
    "df=df[~df['invalid_time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7865bce1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Counts after deletion:\n",
      "invalid_time                0\n",
      "invalid_trip_distance       0\n",
      "inconsistent_fare_amount    0\n",
      "negative_total_amount       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "column_counts_now = df[['invalid_time','invalid_trip_distance', 'inconsistent_fare_amount', 'negative_total_amount']].sum()\n",
    "# Print the results\n",
    "print(\"Column Counts after deletion:\")\n",
    "print(column_counts_now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af18201c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime',\n",
       "       'passenger_count', 'trip_distance', 'RatecodeID', 'store_and_fwd_flag',\n",
       "       'PULocationID', 'DOLocationID', 'payment_type', 'fare_amount', 'extra',\n",
       "       'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge',\n",
       "       'total_amount', 'congestion_surcharge', 'airport_fee', 'invalid_time',\n",
       "       'invalid_trip_distance', 'inconsistent_fare_amount',\n",
       "       'negative_total_amount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961b9fe5",
   "metadata": {},
   "source": [
    "## Ok below is logical test 5 to ensure the dates match and are not in the wrong order. \n",
    "\n",
    "As in no time traveling is occuring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "114dd2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'tpep_pickup_datetime' and 'tpep_dropoff_datetime' to datetime type\n",
    "df['tpep_pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime'])\n",
    "df['tpep_dropoff_datetime'] = pd.to_datetime(df['tpep_dropoff_datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f8db765",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Split 'tpep_pickup_datetime' into date and time columns\n",
    "df['pickup_date'] = df['tpep_pickup_datetime'].dt.date\n",
    "df['pickup_time'] = df['tpep_pickup_datetime'].dt.time\n",
    "\n",
    "# Split 'tpep_dropoff_datetime' into date and time columns\n",
    "df['dropoff_date'] = df['tpep_dropoff_datetime'].dt.date\n",
    "df['dropoff_time'] = df['tpep_dropoff_datetime'].dt.time\n",
    "\n",
    "# Remove the original 'tpep_pickup_datetime' and 'tpep_dropoff_datetime' columns\n",
    "# df = df.drop(['tpep_pickup_datetime', 'tpep_dropoff_datetime'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324b44fc",
   "metadata": {},
   "source": [
    "## Have to check this logic again. It sometimes works. Other times does not. \n",
    "# I got 100 rows in this in one of them and than another time i have 3773428 so have to check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b88946a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with mismatched pickup and dropoff dates: 377428\n"
     ]
    }
   ],
   "source": [
    "# Filter the DataFrame for rows where the pickup and dropoff dates do not match\n",
    "mismatched_dates = df[df['pickup_date'] != df['dropoff_date']]\n",
    "print(\"Number of rows with mismatched pickup and dropoff dates:\", len(mismatched_dates))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a334b082",
   "metadata": {},
   "source": [
    "Below I just dropped the rows of logical test I did."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0990fd3",
   "metadata": {},
   "source": [
    "I just wanted to check i dropped them because I did not for awhile and was wondering what was wrong. I than just wanted to check how many rows i have left and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48f335b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns 'inconsistent_fare_amount', 'negative_total_amount', and 'invalid_trip_distance'\n",
    "dfcnew = df.drop(columns=['invalid_time','inconsistent_fare_amount', 'negative_total_amount', 'invalid_trip_distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "972776cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime',\n",
       "       'passenger_count', 'trip_distance', 'RatecodeID', 'store_and_fwd_flag',\n",
       "       'PULocationID', 'DOLocationID', 'payment_type', 'fare_amount', 'extra',\n",
       "       'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge',\n",
       "       'total_amount', 'congestion_surcharge', 'airport_fee', 'pickup_date',\n",
       "       'pickup_time', 'dropoff_date', 'dropoff_time'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfcnew.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36c9eaf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38846735, 23)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfcnew.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312e0404",
   "metadata": {},
   "source": [
    "I have all the Nans here just to see. None are important to our analysis.Mostly are passenger counts and ratcodeid and store fwd flag including congestion surcharge and airport fee which are not important in our analysis and see to be the same rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3986a6b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN counts for each column:\n",
      "VendorID                       0\n",
      "tpep_pickup_datetime           0\n",
      "tpep_dropoff_datetime          0\n",
      "passenger_count          1282655\n",
      "trip_distance                  0\n",
      "RatecodeID               1282655\n",
      "store_and_fwd_flag       1282655\n",
      "PULocationID                   0\n",
      "DOLocationID                   0\n",
      "payment_type                   0\n",
      "fare_amount                    0\n",
      "extra                          0\n",
      "mta_tax                        0\n",
      "tip_amount                     0\n",
      "tolls_amount                   0\n",
      "improvement_surcharge          0\n",
      "total_amount                   0\n",
      "congestion_surcharge     1282655\n",
      "airport_fee              1282655\n",
      "pickup_date                    0\n",
      "pickup_time                    0\n",
      "dropoff_date                   0\n",
      "dropoff_time                   0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "nan_counts = dfcnew.isna().sum()\n",
    "print(\"NaN counts for each column:\")\n",
    "print(nan_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40e9284c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38846735, 23)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfcnew.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8148524e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete rows with NaN values\n",
    "dfcnew.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "54c5a35a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37564080, 23)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfcnew.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6eaba371",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN counts for each column:\n",
      "VendorID                 0\n",
      "tpep_pickup_datetime     0\n",
      "tpep_dropoff_datetime    0\n",
      "passenger_count          0\n",
      "trip_distance            0\n",
      "RatecodeID               0\n",
      "store_and_fwd_flag       0\n",
      "PULocationID             0\n",
      "DOLocationID             0\n",
      "payment_type             0\n",
      "fare_amount              0\n",
      "extra                    0\n",
      "mta_tax                  0\n",
      "tip_amount               0\n",
      "tolls_amount             0\n",
      "improvement_surcharge    0\n",
      "total_amount             0\n",
      "congestion_surcharge     0\n",
      "airport_fee              0\n",
      "pickup_date              0\n",
      "pickup_time              0\n",
      "dropoff_date             0\n",
      "dropoff_time             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "nan_counts = dfcnew.isna().sum()\n",
    "print(\"NaN counts for each column:\")\n",
    "print(nan_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1391318",
   "metadata": {},
   "source": [
    "I want to see how many duplicates there are and than delete them maybe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed1d586f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "duplicates = dfcnew.duplicated()\n",
    "print(duplicates.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "94a27c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37564080, 23)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfcnew.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f7611f75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "missing_values = duplicates.isnull().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef8a30f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37564080, 23)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfcnew.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dbd52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplicate_rows = dfcnew.duplicated(keep=False)\n",
    "# print(duplicate_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f17f6fb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37564080, 23)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfcnew.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a35be1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaneddata = dfcnew.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f936eed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37564080, 23)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaneddata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce12942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime',\n",
      "       'passenger_count', 'trip_distance', 'RatecodeID', 'store_and_fwd_flag',\n",
      "       'PULocationID', 'DOLocationID', 'payment_type', 'fare_amount', 'extra',\n",
      "       'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge',\n",
      "       'total_amount', 'congestion_surcharge', 'airport_fee', 'pickup_date',\n",
      "       'pickup_time', 'dropoff_date', 'dropoff_time'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(cleaneddata.columns)\n",
    "filtered_table = pa.Table.from_pandas(cleaneddata)\n",
    "pq.write_table(filtered_table, 'cleaneddata.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7a973d",
   "metadata": {},
   "source": [
    "## All below are just for analysing the data. \n",
    "i broke them down into months, hours, and season, holidays. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0900eb",
   "metadata": {},
   "source": [
    "Ok firstly I want the month and I just want to order them because it wasnt ordered in mine. And change it to category this is just for analysis though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dd22c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract the month from the datetime columns\n",
    "cleaneddata['pickup_month'] = cleaneddata['tpep_pickup_datetime'].dt.month_name()\n",
    "cleaneddata['dropoff_month'] = cleaneddata['tpep_dropoff_datetime'].dt.month_name()\n",
    "\n",
    "# Define the desired order of months\n",
    "month_order = ['January', 'February', 'March', 'April', 'May', 'June',\n",
    "               'July', 'August', 'September', 'October', 'November', 'December']\n",
    "\n",
    "# Convert the 'pickup_month' and 'dropoff_month' columns to categorical type with the specified order\n",
    "cleaneddata['pickup_month'] = pd.Categorical(cleaneddata['pickup_month'], categories=month_order, ordered=True)\n",
    "cleaneddata['dropoff_month'] = pd.Categorical(cleaneddata['dropoff_month'], categories=month_order, ordered=True)\n",
    "\n",
    "# Sort the DataFrame by the 'pickup_month' column\n",
    "df = cleaneddata.sort_values('pickup_month')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19feaca",
   "metadata": {},
   "source": [
    "This one is to seperate the time and date into two different columns. Just for easier analysis latewr on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059fa3ce",
   "metadata": {},
   "source": [
    "I have this test to see if the trip was in one day or a few days like. I wanted to see if it was plausible .As in maybe the trip duration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31013417",
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_to_nearest_hour(time):\n",
    "    rounded_time = time.replace(minute=0, second=0)\n",
    "    return rounded_time\n",
    "\n",
    "df['dropoff_time'] = df['dropoff_time'].apply(round_to_nearest_hour)\n",
    "df['pickup_time'] = df['pickup_time'].apply(round_to_nearest_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7834a521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify holidays\n",
    "cal = calendar()\n",
    "holidays = cal.holidays(start='2022-01-01', end='2022-12-31')\n",
    "# Convert 'pickup_date' to datetime-like object\n",
    "df['pickup_date'] = pd.to_datetime(df['pickup_date'])\n",
    "\n",
    "# Check if the pickup date is a holiday and assign day types\n",
    "df['holiday'] = df['pickup_date'].isin(holidays)\n",
    "df['week'] = df['pickup_date'].dt.dayofweek\n",
    "df.loc[df['week'] >= 5, 'day_type'] = \"weekend\"\n",
    "df.loc[df['week'] < 5, 'day_type'] = \"workday\"\n",
    "df.loc[df['holiday'] == True, 'day_type'] = \"holiday\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7aa887",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de26644",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Drop the 'holiday' and 'week' columns\n",
    "# df = df.drop(['holiday', 'week'], axis=1)\n",
    "\n",
    "# Define a function to assign time slots\n",
    "def time_slots(x):\n",
    "    if x.hour in range(6, 12):\n",
    "        return 'Morning'\n",
    "    elif x.hour in range(12, 17):\n",
    "        return 'Afternoon'\n",
    "    elif x.hour in range(17, 22):\n",
    "        return 'Evening'\n",
    "    else:\n",
    "        return 'Late Night'\n",
    "\n",
    "# Apply the time_slots function to 'tpep_pickup_datetime'\n",
    "df['dropoff_timeslots'] = df['dropoff_time'].apply(time_slots)\n",
    "df['pickup_timeslots'] = df['pickup_time'].apply(time_slots)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "# print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2ac945",
   "metadata": {},
   "source": [
    "Ok below is seasons just to make sure I have all the seasons here so that I can analysis the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7dd606",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f87c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "winter_start = pd.to_datetime('2022-01-01').date()\n",
    "winter_end = pd.to_datetime('2022-02-28').date()\n",
    "spring_start = pd.to_datetime('2022-03-01').date()\n",
    "spring_end = pd.to_datetime('2022-05-31').date()\n",
    "summer_start = pd.to_datetime('2022-06-01').date()\n",
    "summer_end = pd.to_datetime('2022-08-31').date()\n",
    "autumn_start = pd.to_datetime('2022-09-01').date()\n",
    "autumn_end = pd.to_datetime('2022-11-30').date()\n",
    "\n",
    "# Set the 'season' value based on the date range\n",
    "df['tpep_pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime']).dt.date\n",
    "df['season'] = pd.NA\n",
    "df.loc[(df['tpep_pickup_datetime'] >= winter_start) & (df['tpep_pickup_datetime'] <= winter_end), 'season'] = 'winter'\n",
    "df.loc[(df['tpep_pickup_datetime'] >= spring_start) & (df['tpep_pickup_datetime'] <= spring_end), 'season'] = 'spring'\n",
    "df.loc[(df['tpep_pickup_datetime'] >= summer_start) & (df['tpep_pickup_datetime'] <= summer_end), 'season'] = 'summer'\n",
    "df.loc[(df['tpep_pickup_datetime'] >= autumn_start) & (df['tpep_pickup_datetime'] <= autumn_end), 'season'] = 'autumn'\n",
    "\n",
    "# Filter the DataFrame for each season\n",
    "winter_data = df[df['season'] == 'winter']\n",
    "spring_data = df[df['season'] == 'spring']\n",
    "summer_data = df[df['season'] == 'summer']\n",
    "autumn_data = df[df['season'] == 'autumn']\n",
    "\n",
    "# Count the number of NaN values in the 'season' column\n",
    "nan_count = df['season'].isna().sum()\n",
    "\n",
    "# Print the results\n",
    "print(\"Number of NaN values in 'season' column:\", nan_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a44d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the unique values for the \"passenger\" column\n",
    "passenger_values = df['passenger_count'].unique()\n",
    "\n",
    "# Print the unique values\n",
    "print(\"Unique passenger values:\")\n",
    "print(passenger_values)\n",
    "\n",
    "# Count the occurrences of each unique value in the \"passenger\" column\n",
    "passenger_counts = df['passenger_count'].value_counts()\n",
    "\n",
    "# Print the counts\n",
    "print(\"Value counts for passenger:\")\n",
    "print(passenger_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a1c12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "passenger_counts = df['passenger_count'].value_counts()\n",
    "\n",
    "# Calculate the percentage for each value\n",
    "passenger_percentage = passenger_counts / len(df) * 100\n",
    "\n",
    "# Print the percentages\n",
    "print(\"Percentage for each passenger count:\")\n",
    "print(passenger_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad3e5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert passenger amount into three level\n",
    "def passenger_convert(row):\n",
    "    if (row >= 1) & (row <= 2):\n",
    "        val = \"small\"\n",
    "    elif (row > 2) & (row < 5):\n",
    "        val = \"medium\"\n",
    "    else:\n",
    "        val = \"high\"\n",
    "    return val\n",
    "\n",
    "df['passenger'] = df['passenger_count'].apply(passenger_convert)\n",
    "df['passenger'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4224ca49",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679a5dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'combined_df' is your DataFrame and 'column1', 'column2', 'column3' are the columns you want to drop\n",
    "combination = df.drop(['trip_distance','VendorID', 'tolls_amount', 'extra','tolls_amount','improvement_surcharge','total_amount','congestion_surcharge','airport_fee','store_and_fwd_flag','tip_amount','mta_tax','payment_type','fare_amount','RatecodeID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6d0f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cf8ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with any missing values\n",
    "combinations = combination.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c51ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combinations.columns)\n",
    "filtered_table = pa.Table.from_pandas(combinations)\n",
    "pq.write_table(filtered_table, 'dataforanalysing.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
