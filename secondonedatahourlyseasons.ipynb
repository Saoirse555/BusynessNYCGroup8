{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e36bd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c75ef352",
   "metadata": {},
   "source": [
    "Below I have code to collect all the parquet files in a list and than concataning the files together and printing them in a wrong way. But because I didn't want to keep doing it. It is commented out. I than have the file being read into them.Than I wanted to check shape and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bce12942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37564080, 23)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaneddata = pd.read_parquet('cleaneddata.parquet')\n",
    "cleaneddata.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6ad867c2",
   "metadata": {},
   "source": [
    "## Manhattan zones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df937966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(263, 7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data for taxi zone\n",
    "zones = pd.read_csv('taxi_zones.csv')\n",
    "zones.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "387acc49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>Shape_Leng</th>\n",
       "      <th>the_geom</th>\n",
       "      <th>Shape_Area</th>\n",
       "      <th>zone</th>\n",
       "      <th>LocationID</th>\n",
       "      <th>borough</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>103</td>\n",
       "      <td>0.014306</td>\n",
       "      <td>MULTIPOLYGON (((-74.04388559600675 40.69018482...</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>Governor's Island/Ellis Island/Liberty Island</td>\n",
       "      <td>103</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>104</td>\n",
       "      <td>0.021221</td>\n",
       "      <td>MULTIPOLYGON (((-74.03995040794244 40.70089063...</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>Governor's Island/Ellis Island/Liberty Island</td>\n",
       "      <td>103</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>105</td>\n",
       "      <td>0.077425</td>\n",
       "      <td>MULTIPOLYGON (((-74.01674756096064 40.69334336...</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>Governor's Island/Ellis Island/Liberty Island</td>\n",
       "      <td>103</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     OBJECTID  Shape_Leng                                           the_geom  \\\n",
       "103       103    0.014306  MULTIPOLYGON (((-74.04388559600675 40.69018482...   \n",
       "104       104    0.021221  MULTIPOLYGON (((-74.03995040794244 40.70089063...   \n",
       "105       105    0.077425  MULTIPOLYGON (((-74.01674756096064 40.69334336...   \n",
       "\n",
       "     Shape_Area                                           zone  LocationID  \\\n",
       "103    0.000006  Governor's Island/Ellis Island/Liberty Island         103   \n",
       "104    0.000012  Governor's Island/Ellis Island/Liberty Island         103   \n",
       "105    0.000369  Governor's Island/Ellis Island/Liberty Island         103   \n",
       "\n",
       "       borough  \n",
       "103  Manhattan  \n",
       "104  Manhattan  \n",
       "105  Manhattan  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter for Manhattan\n",
    "manhattan_zones = zones[zones['borough'] == 'Manhattan']\n",
    "manhattan_zones[manhattan_zones[\"LocationID\"] == 103]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d08c93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 24, 12, 13, 41, 45, 42, 43, 48, 50, 68, 79, 74, 75, 87, 88, 90, 125, 100, 107, 113, 114, 116, 120, 127, 128, 151, 140, 137, 141, 142, 152, 143, 144, 148, 153, 158, 161, 162, 163, 164, 170, 166, 186, 194, 202, 209, 211, 224, 229, 230, 231, 239, 232, 233, 234, 236, 237, 238, 263, 243, 244, 246, 249, 261, 262]\n"
     ]
    }
   ],
   "source": [
    "# Extract location IDs\n",
    "manhattan_ids = manhattan_zones['LocationID'].tolist()\n",
    "manhattan_ids = [x for x in manhattan_ids if x != 103]\n",
    "print(manhattan_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3991a53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataframe to drop rows where neither PULocationID nor DOLocationID is in the Manhattan ID list\n",
    "cleaneddata = cleaneddata[cleaneddata['PULocationID'].isin(manhattan_ids) | cleaneddata['DOLocationID'].isin(manhattan_ids)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "db7a973d",
   "metadata": {},
   "source": [
    "## All below are just for analysing the data. \n",
    "i broke them down into months, hours, and season, holidays. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3e0900eb",
   "metadata": {},
   "source": [
    "Ok firstly I want the month and I just want to order them because it wasnt ordered in mine. And change it to category this is just for analysis though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64dd22c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract the month from the datetime columns\n",
    "cleaneddata['pickup_month'] = cleaneddata['tpep_pickup_datetime'].dt.month_name()\n",
    "cleaneddata['dropoff_month'] = cleaneddata['tpep_dropoff_datetime'].dt.month_name()\n",
    "\n",
    "# Define the desired order of months\n",
    "month_order = ['January', 'February', 'March', 'April', 'May', 'June',\n",
    "               'July', 'August', 'September', 'October', 'November', 'December']\n",
    "\n",
    "# Convert the 'pickup_month' and 'dropoff_month' columns to categorical type with the specified order\n",
    "cleaneddata['pickup_month'] = pd.Categorical(cleaneddata['pickup_month'], categories=month_order, ordered=True)\n",
    "cleaneddata['dropoff_month'] = pd.Categorical(cleaneddata['dropoff_month'], categories=month_order, ordered=True)\n",
    "\n",
    "# Sort the DataFrame by the 'pickup_month' column\n",
    "df = cleaneddata.sort_values('pickup_month')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b19feaca",
   "metadata": {},
   "source": [
    "This one is to seperate the time and date into two different columns. Just for easier analysis latewr on"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "059fa3ce",
   "metadata": {},
   "source": [
    "I have this test to see if the trip was in one day or a few days like. I wanted to see if it was plausible .As in maybe the trip duration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31013417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def round_to_nearest_hour(time):\n",
    "#     rounded_time = time.replace(minute=0, second=0)\n",
    "#     return rounded_time\n",
    "\n",
    "# df['dropoff_time'] = df['dropoff_time'].apply(round_to_nearest_hour)\n",
    "# df['pickup_time'] = df['pickup_time'].apply(round_to_nearest_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7834a521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify holidays\n",
    "cal = calendar()\n",
    "holidays = cal.holidays(start='2022-01-01', end='2022-12-31')\n",
    "# Convert 'pickup_date' to datetime-like object\n",
    "df['pickup_date'] = pd.to_datetime(df['pickup_date'])\n",
    "\n",
    "# Check if the pickup date is a holiday and assign day types\n",
    "df['holiday'] = df['pickup_date'].isin(holidays)\n",
    "df['week'] = df['pickup_date'].dt.dayofweek\n",
    "df.loc[df['week'] >= 5, 'day_type'] = \"weekend\"\n",
    "df.loc[df['week'] < 5, 'day_type'] = \"workday\"\n",
    "df.loc[df['holiday'] == True, 'day_type'] = \"holiday\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f7aa887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5de26644",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Drop the 'holiday' and 'week' columns\n",
    "# df = df.drop(['holiday', 'week'], axis=1)\n",
    "\n",
    "# Define a function to assign time slots\n",
    "def time_slots(x):\n",
    "    if x.hour in range(6, 12):\n",
    "        return 'Morning'\n",
    "    elif x.hour in range(12, 17):\n",
    "        return 'Afternoon'\n",
    "    elif x.hour in range(17, 22):\n",
    "        return 'Evening'\n",
    "    else:\n",
    "        return 'Late Night'\n",
    "\n",
    "# Apply the time_slots function to 'tpep_pickup_datetime'\n",
    "df['dropoff_timeslots'] = df['dropoff_time'].apply(time_slots)\n",
    "df['pickup_timeslots'] = df['pickup_time'].apply(time_slots)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "# print(df.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f2ac945",
   "metadata": {},
   "source": [
    "Ok below is seasons just to make sure I have all the seasons here so that I can analysis the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb7dd606",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8f87c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_year = pd.to_datetime(df['tpep_pickup_datetime']).dt.year.unique()[0]\n",
    "\n",
    "# winter_start = pd.to_datetime('2022-01-01').date()\n",
    "# winter_end = pd.to_datetime('2022-02-28').date()\n",
    "# spring_start = pd.to_datetime('2022-03-01').date()\n",
    "# spring_end = pd.to_datetime('2022-05-31').date()\n",
    "# summer_start = pd.to_datetime('2022-06-01').date()\n",
    "# summer_end = pd.to_datetime('2022-08-31').date()\n",
    "# autumn_start = pd.to_datetime('2022-09-01').date()\n",
    "# autumn_end = pd.to_datetime('2022-11-30').date()\n",
    "\n",
    "# # Set the 'season' value based on the date range\n",
    "# df['tpep_pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime']).dt.date\n",
    "# df['season'] = pd.NA\n",
    "# df.loc[(df['tpep_pickup_datetime'] >= winter_start) & (df['tpep_pickup_datetime'] <= winter_end), 'season'] = 'winter'\n",
    "# df.loc[(df['tpep_pickup_datetime'] >= spring_start) & (df['tpep_pickup_datetime'] <= spring_end), 'season'] = 'spring'\n",
    "# df.loc[(df['tpep_pickup_datetime'] >= summer_start) & (df['tpep_pickup_datetime'] <= summer_end), 'season'] = 'summer'\n",
    "# df.loc[(df['tpep_pickup_datetime'] >= autumn_start) & (df['tpep_pickup_datetime'] <= autumn_end), 'season'] = 'autumn'\n",
    "\n",
    "# # Filter the DataFrame for each season\n",
    "# winter_data = df[df['season'] == 'winter']\n",
    "# spring_data = df[df['season'] == 'spring']\n",
    "# summer_data = df[df['season'] == 'summer']\n",
    "# autumn_data = df[df['season'] == 'autumn']\n",
    "\n",
    "# # Count the number of NaN values in the 'season' column\n",
    "# nan_counts = df['season'].isna().sum()\n",
    "\n",
    "# # Print the results\n",
    "# print(\"Number of NaN values in 'season' column:\", nan_counts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "33c70220",
   "metadata": {},
   "source": [
    "## THE ONE BELOW SHOULD WORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b91d7d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN values in 'season' column: 0\n"
     ]
    }
   ],
   "source": [
    "# Extract the month from the pickup datetime column\n",
    "df['pickup_month'] = pd.to_datetime(df['tpep_pickup_datetime']).dt.month_name()\n",
    "\n",
    "# Set the 'season' value based on the month\n",
    "df['season'] = pd.NA\n",
    "df.loc[df['pickup_month'].isin(['December', 'January', 'February']), 'season'] = 'winter'\n",
    "df.loc[df['pickup_month'].isin(['March', 'April', 'May']), 'season'] = 'spring'\n",
    "df.loc[df['pickup_month'].isin(['June', 'July', 'August']), 'season'] = 'summer'\n",
    "df.loc[df['pickup_month'].isin(['September', 'October', 'November']), 'season'] = 'autumn'\n",
    "\n",
    "# Filter the DataFrame for each season\n",
    "winter_data = df[df['season'] == 'winter']\n",
    "spring_data = df[df['season'] == 'spring']\n",
    "summer_data = df[df['season'] == 'summer']\n",
    "autumn_data = df[df['season'] == 'autumn']\n",
    "\n",
    "# Count the number of NaN values in the 'season' column\n",
    "nan_counts = df['season'].isna().sum()\n",
    "\n",
    "# Print the results\n",
    "print(\"Number of NaN values in 'season' column:\", nan_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36a44d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get the unique values for the \"passenger\" column\n",
    "# passenger_values = df['passenger_count'].unique()\n",
    "\n",
    "# # Print the unique values\n",
    "# print(\"Unique passenger values:\")\n",
    "# print(passenger_values)\n",
    "\n",
    "# # Count the occurrences of each unique value in the \"passenger\" column\n",
    "# passenger_counts = df['passenger_count'].value_counts()\n",
    "\n",
    "# # Print the counts\n",
    "# print(\"Value counts for passenger:\")\n",
    "# print(passenger_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7a1c12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# passenger_counts = df['passenger_count'].value_counts()\n",
    "\n",
    "# # Calculate the percentage for each value\n",
    "# passenger_percentage = passenger_counts / len(df) * 100\n",
    "\n",
    "# # Print the percentages\n",
    "# print(\"Percentage for each passenger count:\")\n",
    "# print(passenger_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4224ca49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df.dtypes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "679a5dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'combined_df' is your DataFrame and 'column1', 'column2', 'column3' are the columns you want to drop\n",
    "combination = df.drop(['trip_distance','VendorID', 'tolls_amount', 'extra','tolls_amount','improvement_surcharge','total_amount','congestion_surcharge','airport_fee','store_and_fwd_flag','tip_amount','mta_tax','payment_type','fare_amount','RatecodeID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6d0f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(combination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45be4132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nan_counts = combination.isna().sum()\n",
    "# print(\"NaN counts for each column:\")\n",
    "# print(nan_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cf8ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with any missing values\n",
    "combination = combination.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c51ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(combination.columns)\n",
    "filtered_table = pa.Table.from_pandas(combination)\n",
    "pq.write_table(filtered_table, 'dataforanalysing.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
